{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Setup"
      ],
      "metadata": {
        "id": "35BJMpOJxB0n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mieKc8lHwInv"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ],
      "metadata": {
        "id": "TJ9GOibHwMHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Document Loading"
      ],
      "metadata": {
        "id": "fynwzT1FxGOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading not needed \"done in chatbot-1\"\n",
        "#loaders = [\n",
        "#    PyPDFLoader(\"rfc7540.pdf\"),\n",
        "#    PyPDFLoader(\"rfc7541.pdf\")\n",
        "#]\n",
        "#docs = []\n",
        "#for loader in loaders:\n",
        "#    docs.extend(loader.load())"
      ],
      "metadata": {
        "id": "wjl1Vd3ywOK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Document Splitting"
      ],
      "metadata": {
        "id": "B_HcArdLxIr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spliting not needed \"done in chatbot-1\"\n",
        "#text_splitter = RecursiveCharacterTextSplitter(\n",
        "#    chunk_size = 1500,\n",
        "#    chunk_overlap = 150\n",
        "#)"
      ],
      "metadata": {
        "id": "grbzQZjuwRkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "Efzd2nVVwTiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorstores and Embedding"
      ],
      "metadata": {
        "id": "dT7OXdDSxMZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'docs/chroma/'\n",
        "embedding = HuggingFaceEmbeddings()\n",
        "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
      ],
      "metadata": {
        "id": "5WrV8SMcwVLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrival"
      ],
      "metadata": {
        "id": "T6FGMCRbxQoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "GTtx2eu_wXNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrival not needed \"done in chatbot-1\"\n",
        "#qa_chain_mr = RetrievalQA.from_chain_type(\n",
        "#    llm,\n",
        "#    retriever=vectordb.as_retriever(),\n",
        "#    chain_type=\"refine\"\n",
        "#)\n",
        "#result = qa_chain_mr({\"query\": question})\n",
        "#result[\"result\"]"
      ],
      "metadata": {
        "id": "c7QmCRnEwah8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memory"
      ],
      "metadata": {
        "id": "EO47kKRhxTej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")"
      ],
      "metadata": {
        "id": "LWDMpuGUwcgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question Answering"
      ],
      "metadata": {
        "id": "Qswwy6r6xhLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=vectordb.as_retriever()\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "YWpmRZ5gweWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = input(\"question\")\n",
        "result = qa({\"question\": question})\n",
        "result[\"answer\"]"
      ],
      "metadata": {
        "id": "zT8FbiEtwfzv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}